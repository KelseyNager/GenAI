{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM9okGaXG7QvQGAJyHcqAi4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KelseyNager/GenAI/blob/main/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational Autoencoders on the SVHN Dataset\n",
        "\n",
        "###Kelsey Nager\n",
        "###CSC 330\n",
        "###The goal of this assignment is create and train a Variational Autoencoder model in Keras to learn representations of the Street View House Numbers dataset and explore its performance with different latent dimensions."
      ],
      "metadata": {
        "id": "FUn38gtWvDMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Preprocess Data"
      ],
      "metadata": {
        "id": "RFlHMx5YvTiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers, utils, datasets\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, ReLU, BatchNormalization, Dropout\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    datasets,\n",
        "    callbacks,\n",
        "    losses,\n",
        "    optimizers,\n",
        "    metrics,\n",
        ")\n",
        "\n",
        "from scipy.stats import norm\n",
        "from scipy.io import loadmat"
      ],
      "metadata": {
        "id": "SNzzbUZmjA1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3edb8a3-556b-4e1b-b539-35dcdcf35a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.13.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GVTXG5VHvPWe",
        "outputId": "b0553778-9349-4a57-d56b-fc49a2a976b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.13.0\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.66.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.12.1)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (18.1.1)\n",
            "Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13.0)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.4.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.0)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
            "Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydantic 2.9.2 requires typing-extensions>=4.6.1; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.23.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.13.0 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.13.0 which is incompatible.\n",
            "torch 2.4.0+cpu requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-1.24.3 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "numpy",
                  "tensorboard",
                  "tensorflow"
                ]
              },
              "id": "3d8278002c72447db4b38df1843e7504"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEE_US4dvB_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8d6f8d-0afb-4ab0-afc2-f426630486fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-09 23:47:55--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182040794 (174M) [text/plain]\n",
            "Saving to: ‘train_32x32.mat’\n",
            "\n",
            "train_32x32.mat     100%[===================>] 173.61M  2.99MB/s    in 51s     \n",
            "\n",
            "2024-10-09 23:48:46 (3.41 MB/s) - ‘train_32x32.mat’ saved [182040794/182040794]\n",
            "\n",
            "--2024-10-09 23:48:46--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64275384 (61M) [text/plain]\n",
            "Saving to: ‘test_32x32.mat’\n",
            "\n",
            "test_32x32.mat      100%[===================>]  61.30M  5.37MB/s    in 26s     \n",
            "\n",
            "2024-10-09 23:49:11 (2.39 MB/s) - ‘test_32x32.mat’ saved [64275384/64275384]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
        "!wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and Pre-Processing"
      ],
      "metadata": {
        "id": "llPCMjPZmSke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = loadmat('train_32x32.mat')\n",
        "test_data = loadmat('test_32x32.mat')\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = np.transpose(train_data['X'], (3, 0, 1, 2)).astype('float32') / 255.0\n",
        "y_train = train_data['y'].flatten()\n",
        "x_test = np.transpose(test_data['X'], (3, 0, 1, 2)).astype('float32') / 255.0\n",
        "y_test = test_data['y'].flatten()\n",
        "\n",
        "# Display the shape of the datasets\n",
        "print(f'Training data shape: {x_train.shape}')\n",
        "print(f'Test data shape: {x_test.shape}')"
      ],
      "metadata": {
        "id": "0pEqB5b1vMV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55924481-7f0b-495a-9ac8-603329794688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (73257, 32, 32, 3)\n",
            "Test data shape: (26032, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build VAE\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xTvBHAayvTsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = K.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "GqNqZEg7vd_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_input = layers.Input(\n",
        "    shape=(32, 32, 1), name=\"encoder_input\"\n",
        ")\n",
        "x = layers.Conv2D(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(\n",
        "    encoder_input\n",
        ")\n",
        "x = layers.Conv2D(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2D(128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "z_mean = layers.Dense(2, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(2, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "pcpPEZmPwmOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb94690-ab42-494d-8ced-f200eb081132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)  [(None, 32, 32, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 16, 16, 32)           320       ['encoder_input[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 64)             18496     ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)            73856     ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 2048)                 0         ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " z_mean (Dense)              (None, 2)                    4098      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " z_log_var (Dense)           (None, 2)                    4098      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " sampling (Sampling)         (None, 2)                    0         ['z_mean[0][0]',              \n",
            "                                                                     'z_log_var[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 100868 (394.02 KB)\n",
            "Trainable params: 100868 (394.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "\n",
        "decoder_input = layers.Input(shape=(2,), name=\"decoder_input\")\n",
        "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = layers.Reshape(shape_before_flattening)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    128, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    64, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    32, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(x)\n",
        "decoder_output = layers.Conv2D(\n",
        "    1,\n",
        "    (3, 3),\n",
        "    strides=1,\n",
        "    activation=\"sigmoid\",\n",
        "    padding=\"same\",\n",
        "    name=\"decoder_output\",\n",
        ")(x)\n",
        "\n",
        "decoder = models.Model(decoder_input, decoder_output)\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "OybBiOzIwmfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a17582-22ee-4089-c857-ed3a9ddc3634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2048)              6144      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 8, 8, 128)         147584    \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 16, 16, 64)        73792     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 32, 32, 32)        18464     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " decoder_output (Conv2D)     (None, 32, 32, 1)         289       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 246273 (962.00 KB)\n",
            "Trainable params: 246273 (962.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(models.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Call the model on a particular input.\"\"\"\n",
        "        z_mean, z_log_var, z = encoder(inputs)\n",
        "        reconstruction = decoder(z)\n",
        "        return z_mean, z_log_var, reconstruction\n",
        "\n",
        "    def train_step(self, data):\n",
        "        \"\"\"Step run during training.\"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, reconstruction = self(data)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                500\n",
        "                * losses.binary_crossentropy(\n",
        "                    data, reconstruction, axis=(1, 2, 3)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    -0.5\n",
        "                    * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),axis=1,\n",
        "                )\n",
        "            )\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        \"\"\"Step run during validation.\"\"\"\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "\n",
        "        z_mean, z_log_var, reconstruction = self(data)\n",
        "        reconstruction_loss = tf.reduce_mean(\n",
        "            500\n",
        "            * losses.binary_crossentropy(data, reconstruction, axis=(1, 2, 3))\n",
        "        )\n",
        "        kl_loss = tf.reduce_mean(\n",
        "            tf.reduce_sum(\n",
        "                -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "                axis=1,\n",
        "            )\n",
        "        )\n",
        "        total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "        return {\n",
        "            \"loss\": total_loss,\n",
        "            \"reconstruction_loss\": reconstruction_loss,\n",
        "            \"kl_loss\": kl_loss,\n",
        "        }"
      ],
      "metadata": {
        "id": "cCMKOPc1yCt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a variational autoencoder\n",
        "vae = VAE(encoder, decoder)"
      ],
      "metadata": {
        "id": "Ofw2txwqm4T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CallBack Set up"
      ],
      "metadata": {
        "id": "sB2_XtBHokDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    'vae_model.h5',  # Path where the model will be saved\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    mode='min',  # We want the minimum loss\n",
        "    verbose=1  # Print messages when saving\n",
        ")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=10,  # Stop training after 10 epochs with no improvement\n",
        "    verbose=1  # Print messages when stopping\n",
        ")"
      ],
      "metadata": {
        "id": "DPrzQiR9oib5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model with Callbacks"
      ],
      "metadata": {
        "id": "0u2pKSkfviVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dims = [2, 5, 10]\n",
        "for dim in latent_dims:\n",
        "    print(f'Training VAE with latent dimension: {dim}')\n",
        "    vae = build_vae(latent_dim=dim)\n",
        "    vae.compile(optimizer='adam', loss=losses.binary_crossentropy)\n",
        "    history = vae.fit(x_train, x_train, epochs=50, batch_size=64, validation_data=(x_test, x_test), callbacks=[checkpoint_callback, early_stopping_callback])"
      ],
      "metadata": {
        "id": "yj1Oayt8vjQz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "b40849df-21bf-4baa-8caf-a9a6e9e81058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training VAE with latent dimension: 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'build_vae' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cbb6146f9a60>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlatent_dims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training VAE with latent dimension: {dim}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_vae' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load saved model"
      ],
      "metadata": {
        "id": "86xeRa9y0ZLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "vae = load_model('vae_model.h5', custom_objects={'vae_loss': vae_loss})"
      ],
      "metadata": {
        "id": "7pyql2AjpMTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue training the loaded model"
      ],
      "metadata": {
        "id": "x0hN3Ich0cdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = vae.fit(\n",
        "    train_data,\n",
        "    epochs=additional_epochs,  # Additional epochs to train\n",
        "    batch_size=32,\n",
        "    validation_data=(val_data, val_data),\n",
        "    callbacks=[checkpoint_callback, early_stopping_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "pox5tuDRpQB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select a subset of the test set\n",
        "n_to_predict = 5000\n",
        "example_images = x_test[:n_to_predict]\n",
        "example_labels = y_test[:n_to_predict]"
      ],
      "metadata": {
        "id": "xpVBXnYu1UhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create autoencoder predictions and display\n",
        "z_mean, z_log_var, reconstructions = vae.predict(example_images)\n",
        "print(\"Example real clothing items\")\n",
        "display(example_images)\n",
        "print(\"Reconstructions\")\n",
        "display(reconstructions)"
      ],
      "metadata": {
        "id": "h2B_o09f1WOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Encode the example images\n",
        "z_mean, z_var, z = encoder.predict(example_images)"
      ],
      "metadata": {
        "id": "BWhKicgo1bLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization\n",
        "\n",
        "\n",
        "###do we need to include examples of the embeddings, encoded points?"
      ],
      "metadata": {
        "id": "vPefJRsfvlYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some examples of the embeddings\n",
        "print(z[:10])"
      ],
      "metadata": {
        "id": "JU3NhJZS1dkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the encoded points in 2D space\n",
        "figsize = 8\n",
        "\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "plt.scatter(z[:, 0], z[:, 1], c=\"black\", alpha=0.5, s=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7V8PS85e1dxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample some points in the latent space, from the standard normal distribution\n",
        "grid_width, grid_height = (6, 3)\n",
        "z_sample = np.random.normal(size=(grid_width * grid_height, 2))"
      ],
      "metadata": {
        "id": "mg4uEvE_1os-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the sampled points\n",
        "reconstructions = decoder.predict(z_sample)"
      ],
      "metadata": {
        "id": "6zd9qPDY1o0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert original embeddings and sampled embeddings to p-values\n",
        "p = norm.cdf(z)\n",
        "p_sample = norm.cdf(z_sample)"
      ],
      "metadata": {
        "id": "96KOhatO1o4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw a plot of...\n",
        "figsize = 8\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "\n",
        "# ... the original embeddings ...\n",
        "plt.scatter(z[:, 0], z[:, 1], c=\"black\", alpha=0.5, s=2)\n",
        "\n",
        "# ... and the newly generated points in the latent space\n",
        "plt.scatter(z_sample[:, 0], z_sample[:, 1], c=\"#00B0F0\", alpha=1, s=40)\n",
        "plt.show()\n",
        "\n",
        "# Add underneath a grid of the decoded images\n",
        "fig = plt.figure(figsize=(figsize, grid_height * 2))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "for i in range(grid_width * grid_height):\n",
        "    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n",
        "    ax.axis(\"off\")\n",
        "    ax.text(\n",
        "        0.5,\n",
        "        -0.35,\n",
        "        str(np.round(z_sample[i, :], 1)),\n",
        "        fontsize=10,\n",
        "        ha=\"center\",\n",
        "        transform=ax.transAxes,\n",
        "    )\n",
        "    ax.imshow(reconstructions[i, :, :], cmap=\"Greys\")"
      ],
      "metadata": {
        "id": "J7GXNPC_1tco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore Latent Space"
      ],
      "metadata": {
        "id": "FClJUhvt15bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colour the embeddings by their label (clothing type - see table)\n",
        "figsize = 8\n",
        "fig = plt.figure(figsize=(figsize * 2, figsize))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "plot_1 = ax.scatter(\n",
        "    z[:, 0], z[:, 1], cmap=\"rainbow\", c=example_labels, alpha=0.8, s=3\n",
        ")\n",
        "plt.colorbar(plot_1)\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "plot_2 = ax.scatter(\n",
        "    p[:, 0], p[:, 1], cmap=\"rainbow\", c=example_labels, alpha=0.8, s=3\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IN5QFV_UvqHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colour the embeddings by their label (clothing type - see table)\n",
        "figsize = 12\n",
        "grid_size = 15\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "plt.scatter(\n",
        "    p[:, 0], p[:, 1], cmap=\"rainbow\", c=example_labels, alpha=0.8, s=300\n",
        ")\n",
        "plt.colorbar()\n",
        "\n",
        "x = norm.ppf(np.linspace(0, 1, grid_size))\n",
        "y = norm.ppf(np.linspace(1, 0, grid_size))\n",
        "xv, yv = np.meshgrid(x, y)\n",
        "xv = xv.flatten()\n",
        "yv = yv.flatten()\n",
        "grid = np.array(list(zip(xv, yv)))\n",
        "\n",
        "reconstructions = decoder.predict(grid)\n",
        "# plt.scatter(grid[:, 0], grid[:, 1], c=\"black\", alpha=1, s=10)\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(figsize, figsize))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "for i in range(grid_size**2):\n",
        "    ax = fig.add_subplot(grid_size, grid_size, i + 1)\n",
        "    ax.axis(\"off\")\n",
        "    ax.imshow(reconstructions[i, :, :], cmap=\"Greys\")"
      ],
      "metadata": {
        "id": "xdMJmonw2JZD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}